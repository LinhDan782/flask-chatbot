import os
import json
import time
import requests
import base64
from io import BytesIO
from PIL import Image
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from google import genai
from google.genai import types

# C·∫•u h√¨nh
load_dotenv()
api_key = os.getenv('GEMINI_API_KEY')
client = genai.Client(api_key=api_key)    
MODEL_ID ="gemini-2.5-flash"
# --- SYSTEM INSTRUCTION (T√≠nh nƒÉng: System Prompt & Fine-tuning logic) ---
STATIC_SHOP_INFO = """
- Shop: OLV Boutique
- Website mua h√†ng: https://www.olv.vn/
- ƒê·ªãa ch·ªâ: 224 Yersin, Hi·ªáp Th√†nh, Th·ªß D·∫ßu M·ªôt, B√¨nh D∆∞∆°ng
- Li√™n h·ªá: 0923003158
- Ch√≠nh s√°ch: ƒê·ªïi tr·∫£ 7 ng√†y. Freeship ƒë∆°n > 500k.
"""
SYSTEM_INSTRUCTION = """
B·∫°n l√† Lily - Tr·ª£ l√Ω b√°n h√†ng AI c·ªßa OLV Boutique.
Nhi·ªám v·ª•: T∆∞ v·∫•n ng·∫Øn g·ªçn, ch·ªët ƒë∆°n nhanh, v√† cung c·∫•p link mua h√†ng ch√≠nh x√°c. Giao ti·∫øp th√¢n thi·ªán, chuy√™n nghi·ªáp nh∆∞ m·ªôt nh√¢n vi√™n b√°n h√†ng th·ª±c th·ª• nh∆∞ng v·∫´n gi·ªØ ƒë∆∞·ª£c s·ª± ng·∫Øn g·ªçn, s√∫c t√≠ch.

QUY T·∫ÆC PH·∫¢N H·ªíI (B·∫ÆT BU·ªòC):
1. **NG·∫ÆN G·ªåN**: Tr·∫£ l·ªùi ƒëi th·∫≥ng v√†o v·∫•n ƒë·ªÅ. Kh√¥ng d√πng qu√° nhi·ªÅu t·ª´ c·∫£m th√°n (nh∆∞ "n√†ng ∆°i", "y√™u l·∫Øm") tr·ª´ khi th·ª±c s·ª± c·∫ßn thi·∫øt. Gi·ªõi h·∫°n c√¢u tr·∫£ l·ªùi d∆∞·ªõi 100 t·ª´.
2. **KH√îNG B·ªäA ƒê·∫∂T**: Ch·ªâ t∆∞ v·∫•n c√°c s·∫£n ph·∫©m c√≥ trong "B·ªëi c·∫£nh s·∫£n ph·∫©m" ƒë∆∞·ª£c cung c·∫•p. N·∫øu kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p, h√£y n√≥i "Hi·ªán t·∫°i shop ch∆∞a t√¨m th·∫•y m·∫´u ƒë√≥, b·∫°n tham kh·∫£o c√°c m·∫´u hot n√†y nh√©".
3. **ƒê·ªäNH D·∫†NG LINK**: Khi nh·∫Øc ƒë·∫øn s·∫£n ph·∫©m, B·∫ÆT BU·ªòC d√πng ƒë·ªãnh d·∫°ng Markdown sau ƒë·ªÉ kh√°ch click ƒë∆∞·ª£c: 
   - D√πng g·∫°ch ƒë·∫ßu d√≤ng cho danh s√°ch.
   - V·ªõi s·∫£n ph·∫©m c·ª• th·ªÉ: üëâ **[T√™n s·∫£n ph·∫©m - Gi√°](URL s·∫£n ph·∫©m)**
   - V·ªõi c√¢u h·ªèi v·ªÅ Website/Trang ch·ªß shop: üëâ **[Website Ch√≠nh H√£ng OLV](https://www.olv.vn/)**
   - L∆ØU √ù: Ph·∫£i s·ª≠ d·ª•ng ch√≠nh x√°c URL ƒë∆∞·ª£c cung c·∫•p trong ph·∫ßn "B·ªëi c·∫£nh s·∫£n ph·∫©m", kh√¥ng t·ª± ch·∫ø link. Tuy·ªát ƒë·ªëi kh√¥ng tr·∫£ v·ªÅ link l√† "undefined"
4. **H√åNH ·∫¢NH**: N·∫øu kh√°ch g·ª≠i ·∫£nh, h√£y nh·∫≠n x√©t ng·∫Øn v·ªÅ m√†u s·∫Øc/ki·ªÉu d√°ng r·ªìi g·ª£i √Ω s·∫£n ph·∫©m t∆∞∆°ng t·ª± t·ª´ d·ªØ li·ªáu.

Context (D·ªØ li·ªáu shop):
{shop_info}
"""
SYSTEM_INSTRUCTION = SYSTEM_INSTRUCTION.format(shop_info=STATIC_SHOP_INFO)

# Bi·∫øn to√†n c·ª•c l∆∞u d·ªØ li·ªáu trong RAM
PRODUCT_DATA_TEXT = ""
PRODUCT_LIST_JSON = []
CHAT_SESSIONS = {}

# --- PH·∫¶N 1: H√ÄM CRAWL D·ªÆ LI·ªÜU T·ª∞ ƒê·ªòNG ---
def crawl_olv_data(max_pages=3):
    """H√†m l·∫•y d·ªØ li·ªáu t·ª´ nhi·ªÅu danh m·ª•c, duy·ªát qua nhi·ªÅu trang"""
    categories = {
        "Gi·∫£m gi√°": "https://www.olv.vn/pages/flash-sale",
        "B√°n ch·∫°y": "https://www.olv.vn/collections/san-pham-ban-chay",
        "T·∫•t c·∫£ s·∫£n ph·∫©m": "https://www.olv.vn/collections/tat-ca-san-pham",
    }
    
    crawled_products = []
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    }
    
    print("üöÄ B·∫Øt ƒë·∫ßu c·∫≠p nh·∫≠t d·ªØ li·ªáu t·ª´ OLV...")
    
    for cat_name, base_url in categories.items():
        for page in range(1, max_pages + 1): # V√≤ng l·∫∑p duy·ªát page
            try:
                url = f"{base_url}?page={page}"
                print(f"--- ƒêang truy c·∫≠p: {cat_name} (Trang {page}) ...")
                
                response = requests.get(url, headers=headers, timeout=10)
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # T√¨m kh·ªëi s·∫£n ph·∫©m
                items = soup.find_all('div', class_=['product-block', 'product-item', 'col-md-3'])
                
                if not items:
                    print(f"   ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ·ªü trang {page}, d·ª´ng danh m·ª•c n√†y.")
                    break # H·∫øt s·∫£n ph·∫©m th√¨ d·ª´ng, qua danh m·ª•c kh√°c
                
                for item in items:
                    try:
                        name_tag = item.find(['h3', 'h4'], class_=['pro-name', 'product-title'])
                        price_tag = item.find(['p', 'span'], class_=['pro-price', 'current-price', 'price'])
                        
                        if name_tag and price_tag:
                            name = name_tag.get_text(strip=True)
                            
                            # L·∫•y link v√† x·ª≠ l√Ω link t∆∞∆°ng ƒë·ªëi
                            a_tag = name_tag.find('a')
                            href = a_tag.get('href', '') if a_tag else ""
                            if not href.startswith('http'):
                                product_url = "https://www.olv.vn" + ("" if href.startswith('/') else "/") + href
                            else:
                                product_url = href

                            # X·ª≠ l√Ω gi√°
                            full_price_text = price_tag.get_text(strip=True)
                            clean_price = full_price_text.split('‚Ç´')[0].strip().replace('\n', '') + '‚Ç´'
                            
                            # L·∫•y ·∫£nh
                            img_tag = item.find('img')
                            img_url = "https://theme.hstatic.net/200000039986/1000723835/14/share_fb_home.png?v=999" # ·∫¢nh m·∫∑c ƒë·ªãnh n·∫øu l·ªói
                            if img_tag:
                                raw_img = img_tag.get('data-src') or img_tag.get('src')
                                if raw_img:
                                    if raw_img.startswith('//'):
                                        img_url = "https:" + raw_img
                                    elif raw_img.startswith('http'):
                                        img_url = raw_img

                            # Ki·ªÉm tra tr√πng l·∫∑p ID ho·∫∑c T√™n
                            if not any(p['name'] == name for p in crawled_products):
                                crawled_products.append({
                                    "id": f"OLV_{len(crawled_products)}",
                                    "name": name,
                                    "price": clean_price,
                                    "category": cat_name,
                                    "url": product_url,
                                    "image_url": img_url
                                })
                    except Exception as loop_e:
                        continue
            except Exception as e:
                print(f"‚ùå L·ªói trang {page}: {e}")
                continue
                                    
    if len(crawled_products) == 0:
        return None
        
    print(f"‚úÖ ƒê√£ crawl xong t·ªïng c·ªông {len(crawled_products)} s·∫£n ph·∫©m.")
    return crawled_products

# --- PH·∫¶N 2: H√ÄM QU·∫¢N L√ù D·ªÆ LI·ªÜU ---
def save_and_reload_data(new_data=None):
    global PRODUCT_DATA_TEXT, PRODUCT_LIST_JSON
    
    #Ch·ªâ ghi file n·∫øu c√≥ d·ªØ li·ªáu m·ªõi ƒë·ªÉ tr√°nh m·∫•t d·ªØ li·ªáu c≈© khi crawl l·ªói
    if new_data and len(new_data) > 0:
        with open('products.json', 'w', encoding='utf-8') as f:
            json.dump(new_data, f, ensure_ascii=False, indent=2)
            print(f"üíæ ƒê√£ l∆∞u {len(new_data)} s·∫£n ph·∫©m m·ªõi v√†o products.json.")

    try:
        if os.path.exists('products.json'):
            with open('products.json', 'r', encoding='utf-8') as f:
                PRODUCT_LIST_JSON = json.load(f)
            
            text_data = ""
            for p in PRODUCT_LIST_JSON:
                text_data += f"- T√™n: {p['name']} | Gi√°: {p['price']} | Nh√≥m: {p.get('category', 'S·∫£n ph·∫©m')}\n"
                text_data += f"  Link: {p['url']}\n---\n"
            
            PRODUCT_DATA_TEXT = text_data
            print("üîÑ ƒê√£ n·∫°p d·ªØ li·ªáu v√†o b·ªô nh·ªõ Bot.")
    except Exception as e:
        print(f"‚ùå L·ªói khi n·∫°p d·ªØ li·ªáu: {e}")
# --- RAG LOGIC (T√¨m ki·∫øm s·∫£n ph·∫©m li√™n quan) ---
def get_relevant_products(query, top_k=5):
    if not query: return ""
    query_lc = query.lower()
    context = ""
    # ∆Øu ti√™n th√¥ng tin Shop n·∫øu kh√°ch h·ªèi link web/ƒë·ªãa ch·ªâ
    if any(k in query_lc for k in ['link', 'web', 'shop', 'ƒë·ªãa ch·ªâ', 'c·ª≠a h√†ng']):
        context += "TH√îNG TIN QUAN TR·ªåNG: Website mua h√†ng l√† https://www.olv.vn/\n\n"
    # T√¨m ki·∫øm ƒë∆°n gi·∫£n (c√≥ th·ªÉ n√¢ng c·∫•p l√™n vector search sau n√†y)
    relevant = [p for p in PRODUCT_LIST_JSON if query_lc in p['name'].lower() or query_lc in p.get('category', '').lower()]
    
    # N·∫øu kh√¥ng t√¨m th·∫•y, l·∫•y t·∫°m 5 s·∫£n ph·∫©m b√°n ch·∫°y/m·ªõi nh·∫•t ƒë·ªÉ g·ª£i √Ω
    if not relevant:
        relevant = PRODUCT_LIST_JSON[:5]
        context += "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m kh·ªõp 100%, nh∆∞ng ƒë√¢y l√† c√°c m·∫´u g·ª£i √Ω:\n"
    else:
        context += "Danh s√°ch s·∫£n ph·∫©m ph√π h·ª£p c√≥ trong kho:\n"
    
    # Format d·ªØ li·ªáu ƒë·∫ßu v√†o cho Gemini th·∫≠t r√µ r√†ng
    for p in relevant[:top_k]:
        context += f"- T√™n: {p['name']}\n  Gi√°: {p['price']}\n  URL: {p['url']}\n\n"
        
    return context
# Kh·ªüi ƒë·ªông l·∫ßn ƒë·∫ßu
save_and_reload_data()

app = Flask(__name__)
CORS(app)

# --- Route 1: Trang ch·ªß (Hi·ªÉn th·ªã giao di·ªán) ---
@app.route('/')
def home():
    return render_template('index.html')
    
# --- Route 2: C·∫≠p nh·∫≠t d·ªØ li·ªáu s·∫£n ph·∫©m ---
@app.route('/admin/update-products', methods=['GET'])
def update_products():
    try:
        # 1. Ch·∫°y Crawler l·∫•y 5 trang ƒë·∫ßu
        new_data = crawl_olv_data(max_pages=5)
        
        # 2. L∆∞u v√† n·∫°p l·∫°i d·ªØ li·ªáu
        save_and_reload_data(new_data)
        
        return jsonify({
            "status": "success", 
            "message": f"ƒê√£ c·∫≠p nh·∫≠t th√†nh c√¥ng {len(new_data)} s·∫£n ph·∫©m m·ªõi nh·∫•t!",
            "total_products": len(new_data)
        })
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)})
# --- Route 3: X√≥a l·ªãch s·ª≠ chat ---
@app.route('/clear_history', methods=['POST'])
def clear_history():
    data = request.json
    session_id = data.get('session_id')
    
    if session_id in CHAT_SESSIONS:
        del CHAT_SESSIONS[session_id] # X√≥a kh·ªèi RAM
        return jsonify({'status': 'success', 'message': 'ƒê√£ x√≥a k√Ω ·ª©c!'})
    return jsonify({'status': 'error', 'message': 'Kh√¥ng t√¨m th·∫•y session'})
# --- Route 4: API Chat ---
@app.route('/chat', methods=['POST'])
def chat():
    data = request.json
    user_msg = data.get('message')
    image_data = data.get('image')
    session_id = data.get('session_id')
    if not user_msg and not image_data:
        return jsonify({'reply': 'B·∫°n ch∆∞a nh·∫≠p g√¨ c·∫£!'})
    # Kh·ªüi t·∫°o l·ªãch s·ª≠ n·∫øu ch∆∞a c√≥
    if session_id not in CHAT_SESSIONS:
        CHAT_SESSIONS[session_id] = client.chats.create(
            model=MODEL_ID,
            config=types.GenerateContentConfig(
                system_instruction=SYSTEM_INSTRUCTION,
                temperature=0.7 # ƒê·ªô s√°ng t·∫°o v·ª´a ph·∫£i ƒë·ªÉ tr·∫£ l·ªùi m∆∞·ª£t m√†
            )
        )
    # RAG: L·∫•y ng·ªØ c·∫£nh s·∫£n ph·∫©m d·ª±a tr√™n tin nh·∫Øn
    product_context = get_relevant_products(user_msg)
# 2. X·ª≠ l√Ω input ng∆∞·ªùi d√πng
    user_parts_for_api = []
    saved_image_bytes = None
    saved_mime_type = "image/jpeg"
    image_payload = None
    if image_data:
        try:
            # T√°ch header v√† payload
            if "," in image_data:
                header, image_payload = image_data.split(",", 1)
                if ":" in header and ";" in header:
                    saved_mime_type = header.split(":")[1].split(";")[0]
            else:
                image_payload = image_data

            # S·ª≠a l·ªói Padding cho Base64
            missing_padding = len(image_payload) % 4
            if missing_padding:
                image_payload += '=' * (4 - missing_padding)

            # Gi·∫£i m√£ 1 l·∫ßn duy nh·∫•t th√†nh bytes
            saved_image_bytes = base64.b64decode(image_payload)
            
            # Chuy·ªÉn ƒë·ªïi sang PIL Image ƒë·ªÉ g·ª≠i cho Gemini
            img = Image.open(BytesIO(saved_image_bytes))
            user_parts_for_api.append(img)
            
        except Exception as e:
            print(f"‚ùå L·ªói x·ª≠ l√Ω ·∫£nh: {e}")
            return jsonify({'reply': 'ƒê·ªãnh d·∫°ng ·∫£nh kh√¥ng h·ª£p l·ªá, b·∫°n g·ª≠i l·∫°i gi√∫p shop nh√©! üå∏'})

    if user_msg:
        user_parts_for_api.append(f"Kh√°ch: {user_msg}")
    
    # K·∫øt h·ª£p tin nh·∫Øn c·ªßa kh√°ch v√† ng·ªØ c·∫£nh s·∫£n ph·∫©m (RAG)
    full_user_query = f"B·ªëi c·∫£nh s·∫£n ph·∫©m: {product_context}\n\nC√¢u h·ªèi kh√°ch h√†ng: {user_msg}"
    content_parts = []
    if saved_image_bytes:
        content_parts.append(types.Part.from_bytes(data=saved_image_bytes, mime_type=saved_mime_type))
    content_parts.append(types.Part.from_text(text=full_user_query))

    try:
        # G·ª≠i ƒë·∫øn Gemini
        response = CHAT_SESSIONS[session_id].send_message(message=content_parts)
        bot_reply = response.text

        # 4. L∆∞u l·∫°i h·ªôi tho·∫°i v√†o RAM
        history_parts = []
        if saved_image_bytes:
            history_parts.append(types.Part.from_bytes(
                data=saved_image_bytes, 
                mime_type=saved_mime_type
            ))
        if user_msg:
            history_parts.append(types.Part.from_text(text=user_msg))
        # T√¨m s·∫£n ph·∫©m ƒë·ªÉ hi·ªÉn th·ªã Card
        product_detail = None
        for p in PRODUCT_LIST_JSON:
            if p['name'].lower() in bot_reply.lower(): 
                product_detail = p
                break 
                
        return jsonify({
            'reply': bot_reply,
            'product_info': product_detail
        })
        
    except Exception as e:
        print(f"‚ùå L·ªói Gemini API: {e}")
        return jsonify({'reply': 'Lily ƒëang b·∫≠n chu·∫©n b·ªã ƒë·ªì m·ªôt ch√∫t, n√†ng ƒë·ª£i x√≠u nh√©! üå∏'})

if __name__ == '__main__':
    #T·ª± ƒë·ªông c·∫≠p nh·∫≠t d·ªØ li·ªáu khi b·∫Øt ƒë·∫ßu ch·∫°y server
    print("‚è≥ ƒêang t·ª± ƒë·ªông c·∫≠p nh·∫≠t s·∫£n ph·∫©m t·ª´ website OLV...")
    try:
        initial_data = crawl_olv_data(max_pages=5)
        if initial_data:
            save_and_reload_data(initial_data)
        else:
            print("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu m·ªõi, s·ª≠ d·ª•ng d·ªØ li·ªáu c≈© t·ª´ file.")
            save_and_reload_data() # N·∫°p l·∫°i d·ªØ li·ªáu c≈© n·∫øu crawl th·∫•t b·∫°i
    except Exception as e:
        print(f"‚ùå L·ªói c·∫≠p nh·∫≠t l√∫c kh·ªüi ƒë·ªông: {e}")
        save_and_reload_data()

    app.run(debug=True)